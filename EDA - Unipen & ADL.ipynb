{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "75aaf693",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from LoadUnipen import LoadUnipen\n",
    "from Testing.CLayer.loadData import load_dataset\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d91816",
   "metadata": {},
   "source": [
    "## Partie Unipen"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37f125a5",
   "metadata": {},
   "source": [
    "Pour Unipen on est censé retrouver des séquences de tailles 50. \"The patterns were preprocessed by re-sampling them to 50 sequence elements\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c399ebe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15578,)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\traz\\Dropbox\\M2\\Stage\\Python\\DTW_Stage\\LoadUnipen.py:99: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X = np.asarray(X)\n"
     ]
    }
   ],
   "source": [
    "X, y = LoadUnipen()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "950e6e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15578"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8f05a7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "uni_len = {}\n",
    "for ts in X:\n",
    "    uni_len[len(ts)] = uni_len.get(len(ts), 0) + 1\n",
    "dstbt = pd.DataFrame.from_dict(uni_len, orient='index', columns=['nb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "54f2637f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nb\n",
      "group               \n",
      "(-0.001, 29.0]  6299\n",
      "(29.0, 57.0]    4515\n",
      "(57.0, 85.0]    3277\n",
      "(85.0, 113.0]   1024\n",
      "(113.0, 141.0]   211\n",
      "(141.0, 169.0]    82\n",
      "(169.0, 203.0]    58\n",
      "(203.0, 246.0]    44\n",
      "(246.0, 319.0]    38\n",
      "(319.0, 868.0]    30\n"
     ]
    }
   ],
   "source": [
    "dstbt[\"group\"] = pd.qcut(dstbt.index, 10)\n",
    "print(dstbt.groupby(\"group\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71827284",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nb           group\n",
      "0  4028  (-0.001, 29.0]\n"
     ]
    }
   ],
   "source": [
    "print(dstbt[dstbt.index==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6e91a8",
   "metadata": {},
   "source": [
    "On voit que la taille des séries varie. Difficile de retrouver 13000 séries avec déjà 4028 qui sont vident (peut être un problème dans ma récupération des données!). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9f9503f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\traz\\AppData\\Local\\Temp\\ipykernel_20144\\1464646224.py:3: RuntimeWarning: Mean of empty slice.\n",
      "  if ts.mean()==0:\n",
      "C:\\Users\\traz\\Anaconda3\\envs\\stageenv\\lib\\site-packages\\numpy\\core\\_methods.py:189: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "208\n"
     ]
    }
   ],
   "source": [
    "nb_null = 0\n",
    "for ts in X:\n",
    "    if ts.mean()==0:\n",
    "        nb_null +=1\n",
    "print(nb_null)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f51ac1",
   "metadata": {},
   "source": [
    "## Partie ADL"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83956ba",
   "metadata": {},
   "source": [
    "Ici on doit trouver des sequences de 200. The time series were also sampled to 200 frames. \"The time series were also sampled to 200 frames. The original experiment [4] uses a median filter, however we found it unnecessary and used the raw data for the experiment.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "16c7a597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\traz\\Dropbox\\M2\\Stage\\Python\\DTW_Stage\\Testing\\CLayer\\loadData.py:273: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_ = np.array(X_seq)\n",
      "C:\\Users\\traz\\Dropbox\\M2\\Stage\\Python\\DTW_Stage\\Testing\\CLayer\\loadData.py:273: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  X_ = np.array(X_seq)\n"
     ]
    }
   ],
   "source": [
    "X_test, y_test, X_train, y_train = load_dataset(\"UCI\", \"ADL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "300254b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "600"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7ca469d",
   "metadata": {},
   "outputs": [],
   "source": [
    "adl_len = {}\n",
    "for ts in X_train:\n",
    "    adl_len[len(ts)] = adl_len.get(len(ts), 0) + 1\n",
    "dstbt = pd.DataFrame.from_dict(adl_len, orient='index', columns=['nb'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "724e62dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  nb\n",
      "group               \n",
      "(124.999, 194.2]  84\n",
      "(194.2, 272.2]    77\n",
      "(272.2, 341.8]    51\n",
      "(341.8, 380.4]    74\n",
      "(380.4, 428.0]    77\n",
      "(428.0, 475.6]    69\n",
      "(475.6, 527.2]    53\n",
      "(527.2, 658.4]    38\n",
      "(658.4, 913.8]    38\n",
      "(913.8, 3153.0]   39\n"
     ]
    }
   ],
   "source": [
    "dstbt[\"group\"] = pd.qcut(dstbt.index, 10)\n",
    "print(dstbt.groupby(\"group\").sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f7e9e10c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille min:  125\n",
      "Taille max:  3153\n"
     ]
    }
   ],
   "source": [
    "print(\"Taille min: \", dstbt.index.min())\n",
    "print(\"Taille max: \", dstbt.index.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1748b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "nb_null = 0\n",
    "for ts in X_train:\n",
    "    if ts.mean()==0:\n",
    "        nb_null +=1\n",
    "print(nb_null)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StageEnv",
   "language": "python",
   "name": "stageenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
